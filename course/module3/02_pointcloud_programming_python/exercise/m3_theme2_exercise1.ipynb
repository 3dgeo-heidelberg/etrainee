{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ce992b7",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary>Metadata</summary> \n",
    "    title: \"E-TRAINEE HELIOS++ exercise for point cloud change analysis\"<br />\n",
    "    description: \"This is an exercise in the second theme within the 3D/4D Geographic Point Cloud Time Series Analysis module.\"<br />\n",
    "    dateCreated: 2022-08<br />\n",
    "    authors: Mark Searle<br />\n",
    "    contributors: Katharina Anders, Bernhard Höfle <br />\n",
    "    estimatedTime: 1.5 hrs\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9544aa8c",
   "metadata": {},
   "source": [
    "# Exercise: Virtual Laser Scanning in HELIOS++ for Point Cloud Change Analysis\n",
    "\n",
    "In this excercise we will be conducting an experiment of surface change analysis using UAV-borne laser scanning (ULS) point clouds and virtually generated airborne laser scanning (ALS) point coulds. Our area of interest (AOI) is a rock glacier in Austria of which UAV point clouds have been acquired repeatedly by the [3DGeo Research Group](https://www.geog.uni-heidelberg.de/3dgeo/index.html) in Heidelberg over the past years. By analysing and comparing the point clouds from different points in time (epochs), it is possible to analyse the movement of the rock glacier.\n",
    "\n",
    "The aim of this exercise is to analyse the difference in surface change detection when acquiring the rock glacier using ULS vs ALS. ALS point clouds generally have lower point densities and therefore lower spatial resolutions as well as lower overall ranging accuracy and may therefore lead to unwanted noise in the change detection. However, ALS can prove to be a more cost-efficient method due to the large coverage areas. For many regions, ALS datasets are available online via national inventory databases. Therefore the option of using ALS data may be considered if the acquired data meets the requirements for any given analysis. Virtual laser scanning (VLS) is a valuable tool that can help us determine whether point clouds from certain LiDAR acquisitions meet the analysis requirements. In this case, we will be analysing whether ALS point clouds of the rock glacier in Austria would deliver valuable results when applying a rudimentary method of surface change analysis.\n",
    "\n",
    "To do so, we will first perform surface change detection between our two epochs of ULS data. Then, we will generate ALS data for each epoch, using the Heidelberg LiDAR Operations Simulator (HELIOS++) and the ULS data as the 3D models which are recorded by the virtual airborne laser scanner. After performing surface change analysis on the ALS data for each epoch, we can compare the results of the ULS and the ALS surface change analysis and determine if there is a noteworthy difference in the results.\n",
    "\n",
    "**Note to start:** HELIOS++ must be installed on your device for this exercise. You can download HELIOS++ from the [HELIOS++ GitHub repo](https://github.com/3dgeo-heidelberg/helios). Additionally, to enable hidden solution cells, you must install the jupyter notebook extension [Exercise](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/exercise/readme.html). Instructions to install jupyter extensions can be found [here](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html).\n",
    "\n",
    "The data for the exercise is located in the directory `ahk` of the course data repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08536b44",
   "metadata": {},
   "source": [
    "In the following cell, we indicate our HELIOS++ root directory from which we will be working. Then, we import the remaining libraries.\n",
    "\n",
    "Important: All data paths need to be indicated with forward slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bb098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "helios_path = \"your/helios/path\"\n",
    "os.chdir(helios_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34e0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pdal \n",
    "import pyhelios\n",
    "from pyhelios import SimulationBuilder\n",
    "from pyhelios.util import flight_planner, scene_writer\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#import xml.etree.ElementTree as ET\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194d55d",
   "metadata": {},
   "source": [
    "### 1. ULS data surface change analysis\n",
    "The ULS data can be seen as the 'ground truth' data for the rock glacier. By conducting a change detection analysis on the ULS data, we get a good estimate of the surface change that occurred between 2020 and 2021.\n",
    "\n",
    "**Method:**\n",
    "For a rudementary form of change detection we will convert both point clouds to height rasters and calculate the difference between the rasters.\n",
    "\n",
    "Please indicate the path of the ULS datasets at points T1 and T2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fda253",
   "metadata": {
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "uls_t1 = \"path-to-data/ahk_2020_uls.laz\"\n",
    "uls_t2 = \"path-to-data/ahk_2021_uls.laz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a6140",
   "metadata": {},
   "source": [
    "**1.1 Create raster from ULS 2020:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee45b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uls_t1_dtm = uls_t1.replace(\".laz\", \"_dtm_1m.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57318223",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "json_dtm = \"\"\"[\n",
    "    \"%s\", \n",
    "    {\n",
    "        \"type\":\"writers.gdal\",\n",
    "        \"filename\": \"%s\",\n",
    "        \"output_type\":\"min\",\n",
    "        \"gdaldriver\":\"GTiff\",\n",
    "        \"resolution\":1.0,\n",
    "        \"window_size\":8\n",
    "    }\n",
    "]\"\"\"%(uls_t1, uls_t1_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135a501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline(json_dtm)\n",
    "exe = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d5afc",
   "metadata": {},
   "source": [
    "*1.1.1 Getting raster dimensions:*\n",
    "\n",
    "For this we will use the python package [rasterio](https://pypi.org/project/rasterio/), which allows us to read and write TIF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecf0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a51fc9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#getting raster dimensions so the dimensions of the second raster can be adapted accordingly\n",
    "\n",
    "with rio.open(uls_t1_dtm) as src:\n",
    "    uls_t1_data = src.read(1, masked=True)\n",
    "    t1_tf = src.transform\n",
    "    t1_bounds = src.bounds\n",
    "    dsm_meta = src.profile\n",
    "    width= src.width\n",
    "    height = src.height\n",
    "    \n",
    "origin_left, origin_bottom, origin_right, origin_top = t1_bounds\n",
    "dsm_width = dsm_meta['width']\n",
    "dsm_height = dsm_meta['height']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6038104",
   "metadata": {},
   "source": [
    "**1.2 Create raster from ULS 2021:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ce77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uls_t2_dtm = uls_t2.replace(\".laz\", \"_dtm_1m.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5066333",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dtm = \"\"\"[\n",
    "    \"%s\",\n",
    "    {\n",
    "        \"type\":\"writers.gdal\",\n",
    "        \"filename\": \"%s\",\n",
    "        \"output_type\":\"min\",\n",
    "        \"gdaldriver\":\"GTiff\",\n",
    "        \"resolution\":1.0,\n",
    "        \"window_size\":8,\n",
    "        \"origin_x\":\"%.3f\",\n",
    "        \"origin_y\":\"%.3f\",\n",
    "        \"width\":\"%i\",\n",
    "        \"height\":\"%i\"\n",
    "    }\n",
    "]\"\"\"% (uls_t2, uls_t2_dtm, origin_left, origin_bottom, dsm_width, dsm_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea51dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline(json_dtm)\n",
    "exe = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7237bf3",
   "metadata": {},
   "source": [
    "**1.3 Calculate difference of rasters:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35823bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(uls_t1_dtm) as src:\n",
    "    uls_t1_data = src.read(1, masked=True)\n",
    "    \n",
    "with rio.open(uls_t2_dtm) as src:\n",
    "    uls_t2_data = src.read(1, masked=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db439136",
   "metadata": {},
   "outputs": [],
   "source": [
    "uls_diff = uls_t1_data - uls_t2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54e4622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(uls_diff, cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bddec1",
   "metadata": {},
   "source": [
    "We can clearly identify the rock glacier by the areas of surface change that we see in the image. Let's save the ULS surface change to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cc6ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uls_diff_file = 'uls_diff.tif'\n",
    "\n",
    "with rio.open(uls_diff_file, 'w', **dsm_meta) as ff:\n",
    "    ff.write(uls_diff, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496948fa",
   "metadata": {},
   "source": [
    "### 2. Generate ALS data\n",
    "\n",
    "Using [HELIOS++](https://github.com/3dgeo-heidelberg/helios), we will now run two virtual laser scanning acquisitions over our 3d-model of the rock glacier at both points in time (2020 & 2021). We will be conducting airborne laser scanning (ALS) acquisitions. Comparing the two virtual ALS datasets will give us an estimate for the change we would have detected in the rock glacier if we had flown two ALS acquisitions. Comparing the detected change by ALS with the change by ULS will indicate the precision/accuracy of the ALS change detection.\n",
    "\n",
    "To make yourself familiar with HELIOS++ and how it works, please consult the [wiki](https://github.com/3dgeo-heidelberg/helios)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969136af",
   "metadata": {},
   "source": [
    "**2.1 Create HELIOS++ scenes**\n",
    "\n",
    "First we must create the XML scenes for our two simulations. The scene files allow you to define the 3d models which will be loaded into HELIOS++ and recorded by the virtual laser scanner. You can read up on scene files in the [HELIOS++ wiki entry](https://github.com/3dgeo-heidelberg/helios/wiki/Scene). If you are not familiar with XML files it might also be sensible to have a look at the [XML wikipedia article](https://de.wikipedia.org/wiki/Extensible_Markup_Language). Each component of a HELIOS++ simulation is defined in an XML file.\n",
    "\n",
    "In our case, the scenes will consist of one TIF file each, representing the surface of the rock glacier at the two points in time. We will write the scenes using the scene_writer, which is part of the util-sub package of pyhelios. You can read up on the scene writer in the [corresponding wiki entry](https://github.com/3dgeo-heidelberg/helios/wiki/pyhelios-%F0%9F%90%8D-The-util-subpackage#the-scene-writer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523a994",
   "metadata": {},
   "source": [
    "*2.1.1 Create sceneparts from DTMs*\n",
    "\n",
    "We first create python instances of out two sceneparts, the DTMs of the rock glacier in 2020 and 2021. To do so, we use the `create_scenepart_tiff` function which is demonstrated in the [corresponding wiki entry](https://github.com/3dgeo-heidelberg/helios/wiki/pyhelios-%F0%9F%90%8D-The-util-subpackage#the-scene-writer). Click on the plus sign to the left of the cell if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95a71cd2",
   "metadata": {
    "scrolled": true,
    "solution": "shown",
    "solution_first": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_scenepart_tiff() missing 1 required positional argument: 'filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sp1 \u001b[38;5;241m=\u001b[39m \u001b[43mscene_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_scenepart_tiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m sp2 \u001b[38;5;241m=\u001b[39m scene_writer\u001b[38;5;241m.\u001b[39mcreate_scenepart_tiff()\n",
      "\u001b[1;31mTypeError\u001b[0m: create_scenepart_tiff() missing 1 required positional argument: 'filepath'"
     ]
    }
   ],
   "source": [
    "sp1 = scene_writer.create_scenepart_tiff()\n",
    "\n",
    "sp2 = scene_writer.create_scenepart_tiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f74de78",
   "metadata": {
    "solution": "shown"
   },
   "outputs": [],
   "source": [
    "sp1 = scene_writer.create_scenepart_tiff(uls_t1_dtm,\n",
    "                               matfile=r\"data/sceneparts/basic/groundplane/groundplane.mtl\",\n",
    "                               matname=\"None\")\n",
    "\n",
    "sp2 = scene_writer.create_scenepart_tiff(uls_t2_dtm,\n",
    "                               matfile=r\"data/sceneparts/basic/groundplane/groundplane.mtl\",\n",
    "                               matname=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b8714",
   "metadata": {},
   "source": [
    "*2.1.2 Build scenes*\n",
    "\n",
    "Next, we build our two scenes. Each scene contains one of the sceneparts created in the previous step, corresponding to the rock glacier in 2020 and 2021. The `build_scene` function allows us to do so. Click on the plus sign to the left of the cell if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3565ff8",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_scene() missing 2 required positional arguments: 'scene_id' and 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scenes \u001b[38;5;241m=\u001b[39m [\u001b[43mscene_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[0;32m      2\u001b[0m           scene_writer\u001b[38;5;241m.\u001b[39mbuild_scene()]\n",
      "\u001b[1;31mTypeError\u001b[0m: build_scene() missing 2 required positional arguments: 'scene_id' and 'name'"
     ]
    }
   ],
   "source": [
    "scenes = [scene_writer.build_scene(), \n",
    "          scene_writer.build_scene()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d8cec3f",
   "metadata": {
    "code_folding": [],
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "scenes = [scene_writer.build_scene(scene_id=\"uls_t1\", name=\"Rock Glacier T1\", sceneparts=[sp1]), \n",
    "          scene_writer.build_scene(scene_id=\"uls_t2\", name=\"Rock Glacier T2\", sceneparts=[sp2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2262cdf",
   "metadata": {},
   "source": [
    "*2.1.3 Write scenefiles*\n",
    "\n",
    "Finally, we write the scenes to XML files which can be read by HELIOS++ to execute the simulations. We give a name to each file and write the content of the scenes we built in the previous step to the files. Click on the plus sign to the left of the cell if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9ce0842",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "scenefiles = ['', '']\n",
    "\n",
    "for i in range(2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4c66dad",
   "metadata": {
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "scenefiles = ['data/scenes/scene_t1.xml', 'data/scenes/scene_t2.xml']\n",
    "\n",
    "for i in range(2):\n",
    "    with open(scenefiles[i], 'w') as f:\n",
    "        f.write(scenes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4a3d7",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "**2.2 Create HELIOS++ surveys**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d5162",
   "metadata": {},
   "source": [
    "The [HELIOS++ XML survey file](https://github.com/3dgeo-heidelberg/helios/wiki/Survey) defines the movement and type of scanner used, as well as the settings of the scanner and the scene to be scanned. In the cell below you can choose an appropriate scanning platform and scanner model for our acquisitions. You can also choose the settings for the surveys, as well as names for the surveys.\n",
    "\n",
    "Take a look at the wiki page for the [scanner](https://github.com/3dgeo-heidelberg/helios/wiki/Scanners) and the [platform](https://github.com/3dgeo-heidelberg/helios/wiki/Platforms) to help you choose the correct platform and scanner ids for ALS acquisitions. The possible scanner settings can be read from the entries for each scanner in the scanner xml file. If you need some help, click on the plus sign to the left of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1160436",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "outputs": [],
   "source": [
    "scanner_xml = 'data/scanners_als.xml'\n",
    "platform_xml = 'data/platforms.xml'\n",
    "scanner_id = ''\n",
    "platform_id = ''\n",
    "pulse_freq = 0\n",
    "scan_freq = 0\n",
    "flight_v = 0\n",
    "alt = 0\n",
    "scan_angle = 0\n",
    "surveys = [\"\", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8680a57",
   "metadata": {
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "scanner_xml = 'data/scanners_als.xml'\n",
    "platform_xml = 'data/platforms.xml'\n",
    "scanner_id = 'leica_als50-ii'\n",
    "platform_id = 'sr22'\n",
    "pulse_freq = 100000\n",
    "scan_freq = 90\n",
    "flight_v = 60\n",
    "alt = 4000\n",
    "scan_angle = 30\n",
    "surveys = [\"data/surveys/als_t1.xml\", \"data/surveys/als_t2.xml\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48934640",
   "metadata": {},
   "source": [
    "**Explanation:** The specifications above mean that we will use the Leica ALS 50-ii which will be mounted on our airborne laser scanning mount, the SR-22. The scanner will operate at a pulse frequency of 100000 Hz and a scan frequency of 90 Hz at a scan angle of +- 30°. The aicraft will be flying at an altitude of 4000 m (above sea level) with a speed of 60 m/s.\n",
    "\n",
    "You will find the ALS 50-ii and its specifications in the file `data/scanners_als.xml` relative to your HELIOS++ directory. The SR-22 mount can be found in the file `data/platforms_als.xml`\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afff54",
   "metadata": {},
   "source": [
    "*2.2.1 Set flight paths*\n",
    "\n",
    "To define our surveys we must determine the flight path of the aircraft. Excecute the following code to set the two flight passes manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9500f626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen your flight lines.\n",
      "Coordinates P1: x=652857.1074354838, y=5189495.766032258\n",
      "Coordinates P2: x=653181.8614677419, y=5188936.887\n"
     ]
    }
   ],
   "source": [
    "def tellme(s):\n",
    "    plt.title(s, fontsize=12)\n",
    "    plt.draw()\n",
    "    \n",
    "n_pos = 4\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "zoom_out = 600\n",
    "\n",
    "plt.imshow(uls_diff, cmap='pink')\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([-zoom_out, np.shape(uls_diff)[1]+zoom_out])\n",
    "ax.set_ylim([np.shape(uls_diff)[0]+zoom_out, -zoom_out])\n",
    "\n",
    "tellme('Now you may select the trajectory of the aircraft carrying the virtual laser scanner.')\n",
    "\n",
    "plt.waitforbuttonpress()\n",
    "\n",
    "while True:\n",
    "    pt = []\n",
    "    while len(pt) < n_pos:\n",
    "        tellme(f'Please choose {n_pos} four positions with the mouse.')\n",
    "        pt = np.asarray(plt.ginput(n_pos, timeout=-1))\n",
    "    line_1 = plt.plot([pt[0][0], pt[1][0]], [pt[0][1], pt[1][1]], label='Pass 1', color='steelblue')\n",
    "    line_2 = plt.plot([pt[2][0], pt[3][0]], [pt[2][1], pt[3][1]], label='Pass 2', color='firebrick')\n",
    "    \n",
    "    ar_length = 10000\n",
    "    arrow_1 = plt.arrow(pt[1][0], pt[1][1], -(pt[0][0]-pt[1][0])/ar_length, (pt[1][1]-pt[0][1])/ar_length, head_width=50, edgecolor='none', facecolor='steelblue')\n",
    "    arrow_2 = plt.arrow(pt[3][0], pt[3][1], -(pt[2][0]-pt[3][0])/ar_length, (pt[3][1]-pt[2][1])/ar_length, head_width=50, edgecolor='none', facecolor='firebrick')\n",
    "    plt.legend()\n",
    "    \n",
    "    tellme('Happy?\\nKeypress for \"Yes\", mouseclick for \"No\"')\n",
    "\n",
    "    if plt.waitforbuttonpress(timeout=-1):\n",
    "        plt.close()\n",
    "        break\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    for art in ax.get_children():\n",
    "        if isinstance(art, matplotlib.patches.FancyArrow) or isinstance(art, matplotlib.lines.Line2D):\n",
    "            art.remove()\n",
    "\n",
    "x1, y1 = t1_tf * (pt[0][0], pt[0][1])\n",
    "x2, y2 = t1_tf * (pt[1][0], pt[1][1])\n",
    "print('You have chosen your flight lines.\\nCoordinates P1: x={}, y={}\\nCoordinates P2: x={}, y={}'.format(x1, y1, x2, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce500c",
   "metadata": {},
   "source": [
    "*2.2.2 Write survey files*\n",
    "\n",
    "Now we can write the selected scan lines to our survey files. In the step below, we write the string containing the simulation legs, that define the movement of the scanner and the settings at each point in time. Have a look at the [wiki entry on simulation legs](https://github.com/3dgeo-heidelberg/helios/wiki/Survey#leg-definition) to find out more.\n",
    "\n",
    "In our case, we take the points selected in the plot in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e98458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs = ''\n",
    "active = True\n",
    "for i in range(4):\n",
    "    if i%2==0:\n",
    "        active = True\n",
    "    else:\n",
    "        active = False\n",
    "    \n",
    "    x, y = t1_tf * (pt[i][0], pt[i][1])\n",
    "    \n",
    "    legs+=f'''\n",
    "    <leg stripId=\"0\">\n",
    "            <platformSettings x=\"{x}\" y=\"{y}\" template=\"platform_als\"/>\n",
    "            <scannerSettings template=\"scanner_als\" active=\"{active}\"/>\n",
    "    </leg>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64539e87",
   "metadata": {},
   "source": [
    "The main survey content contains templates for the scan settings as well as the platform settings which can then be applied to each leg. We also define the name of the platform to be used in the survey as well as the scanner model and the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "527f5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_content = f'''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<document>\n",
    "    <platformSettings id=\"platform_als\" movePerSec_m=\"{flight_v}\" z=\"{alt}\" />\n",
    "    <scannerSettings active=\"true\" id=\"scanner_als\" pulseFreq_hz=\"{pulse_freq}\" scanAngle_deg=\"{scan_angle}\" scanFreq_hz=\"{scan_freq}\" trajectoryTimeInterval_s=\"0.01\"/>\n",
    "    <survey name=\"als_rock_glacier\" platform=\"{platform_xml}#{platform_id}\" scanner=\"{scanner_xml}#{scanner_id}\" scene=\"\">\n",
    "    <FWFSettings beamSampleQuality=\"5\" winSize_ns=\"1.5\"/>\n",
    "    {legs}\n",
    "    </survey>\n",
    "</document>\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba779d0",
   "metadata": {},
   "source": [
    "To distinguish our surveys from each other we must assign them each their corresponding scene file and a unique survey id. In this case `als_rock_glacier_t1` and `als_rock_glacier_t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1a020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing survey...\n",
      "Filename: data/surveys/als_t1.xml\n",
      "Survey ID: als_rock_glacier_t1\n",
      "Scene: data/scenes/scene_t1.xml#uls_t1\n",
      "\n",
      "Writing survey...\n",
      "Filename: data/surveys/als_t2.xml\n",
      "Survey ID: als_rock_glacier_t2\n",
      "Scene: data/scenes/scene_t2.xml#uls_t2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    scene_name = scenefiles[i] + '#' + 'uls_t{}'.format(i+1)\n",
    "    survey_id = 'als_rock_glacier_t{}'.format(i+1)\n",
    "    \n",
    "    print('Writing survey...\\nFilename: {}\\nSurvey ID: {}\\nScene: {}\\n'.format(surveys[i], survey_id, scene_name))\n",
    "    \n",
    "    with open(surveys[i], 'w') as f:\n",
    "        f.write(survey_content.replace('scene=\"\"', 'scene=\"{}\"'.format(scene_name)).replace(\n",
    "        'als_rock_glacier', survey_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4b0a2",
   "metadata": {},
   "source": [
    "**2.3 Run HELIOS++ surveys**\n",
    "\n",
    "Next, we run our simulations, using the HELIOS++ python bindings, `pyhelios`. There is a [wiki entry](https://github.com/3dgeo-heidelberg/helios/wiki/Python-bindings-%F0%9F%90%8D-Getting-started) designated to pyhelios where you can read up on the basic usage.\n",
    "\n",
    "Since our working directory is already the helios root directory, we can get started right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91e0cc",
   "metadata": {},
   "source": [
    "*2.3.1 Set HELIOS++ environment*\n",
    "\n",
    "First we set the desired logging verbosity as well as a randomness seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa9e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging.\n",
    "#pyhelios.loggingSilent()\n",
    "#pyhelios.loggingQuiet()\n",
    "pyhelios.loggingDefault()\n",
    "#pyhelios.loggingVerbose()\n",
    "#pyhelios.loggingVerbose2()\n",
    "\n",
    "# Set seed for random number generator.\n",
    "pyhelios.setDefaultRandomnessGeneratorSeed(\"123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434aba23",
   "metadata": {},
   "source": [
    "*2.3.2 Build simulations and run surveys*\n",
    "\n",
    "Now we build and run the simulation for each of the two survey files we created in the previous steps. The for-loop iterates over both our simulations and builds and executes them consecutively.\n",
    "\n",
    "**Note:** If you are running jupyter from a console window you can watch the output of the HELIOS++ simulations there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fea1d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimulationBuilder is building simulation ...\n",
      "SimulationBuilder built simulation in 13.413351799999987 seconds\n",
      "Simulation has started!\n",
      "Survey Name: als_rock_glacier_t1\n",
      "Scanner: leica_als50-ii Power: 4.000000 W Divergence: 0.220000 mrad Wavelength: 1064 nm Visibility: 23.000000 km\n",
      "Simulation has been running for 0 min and 30 sec. Please wait.\n",
      "Simulation has finished!\n",
      "SimulationBuilder is building simulation ...\n",
      "SimulationBuilder built simulation in 13.161589699999922 seconds\n",
      "Simulation has started!\n",
      "Survey Name: als_rock_glacier_t2\n",
      "Scanner: leica_als50-ii Power: 4.000000 W Divergence: 0.220000 mrad Wavelength: 1064 nm Visibility: 23.000000 km\n",
      "Simulation has been running for 0 min and 30 sec. Please wait.\n",
      "Simulation has finished!\n"
     ]
    }
   ],
   "source": [
    "outfiles = []\n",
    "\n",
    "for survey in surveys:\n",
    "    # use SimulationBuilder to configure simulation\n",
    "    simB = SimulationBuilder(str(survey), \"assets/\", \"output/\")\n",
    "    simB.setLasOutput(True)\n",
    "    simB.setZipOutput(True)\n",
    "    simB.setCallbackFrequency(10000)\n",
    "    \n",
    "    # build the simulation\n",
    "    sim = simB.build()\n",
    "    \n",
    "    # Start the simulation.\n",
    "    start_time = time.time()\n",
    "    sim.start()\n",
    "\n",
    "    if sim.isStarted():\n",
    "        print('Simulation has started!\\nSurvey Name: {survey_name}\\n{scanner_info}'.format(\n",
    "            survey_name = sim.sim.getSurvey().name,\n",
    "            scanner_info = sim.sim.getScanner().toString()))\n",
    "\n",
    "    while sim.isRunning():\n",
    "        duration = time.time()-start_time\n",
    "        mins = duration // 60\n",
    "        secs = duration % 60\n",
    "        print(\"\\r\"+\"Simulation has been running for {} min and {} sec. Please wait.\".format(int(mins), int(secs)), end=\"\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    if sim.isFinished():\n",
    "        print(\"\\n\"+\"Simulation has finished!\")\n",
    "    \n",
    "    output = sim.join()\n",
    "        \n",
    "    outfiles.append(output.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee186b5f",
   "metadata": {},
   "source": [
    "### 3. ALS data surface change analysis\n",
    "\n",
    "The HELIOS++ acquisitions have left us with two point clouds, representing ALS acquisitions of the rock glacier in 2020 and 2021 respectively. The filenames of the ouptut were stored in the `outfiles` python list after completion of each simulation.\n",
    "\n",
    "As we did for the ULS data, we will now convert both point clouds to height rasters, and calculate the difference of the two rasters as a rudimentary form of surface change analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a064828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS point clouds located at:\n",
      "\n",
      "output\\\\Survey Playback\\\\als_rock_glacier_t1\\\\2022-12-13_17-26-45\\\\points\\\\strip000_point.laz\n",
      "and\n",
      "output\\\\Survey Playback\\\\als_rock_glacier_t2\\\\2022-12-13_17-27-30\\\\points\\\\strip000_point.laz\n"
     ]
    }
   ],
   "source": [
    "from pathlib import PurePath\n",
    "als_t1 = str(PurePath(outfiles[0])).replace('\\\\', '\\\\\\\\')\n",
    "als_t2 = str(PurePath(outfiles[1])).replace('\\\\', '\\\\\\\\')\n",
    "\n",
    "print(f'ALS point clouds located at:\\n\\n{als_t1}\\nand\\n{als_t2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544f848",
   "metadata": {},
   "source": [
    "**3.1 Create raster from ALS 2020:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8c73165",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_t1_dtm = als_t1.replace(\".laz\", \"_dtm_1m.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f138509",
   "metadata": {},
   "source": [
    "Execute the following code in order to fix the global encoding of the HELIOS-generated point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7238c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = als_t1\n",
    "f = open(filename, \"rb+\")\n",
    "f.seek(6)\n",
    "f.write(bytes([17, 0, 0, 0]));\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef218c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dtm = \"\"\"[\n",
    "    \"%s\",\n",
    "    {\n",
    "        \"type\":\"writers.gdal\",\n",
    "        \"filename\": \"%s\",\n",
    "        \"output_type\":\"min\",\n",
    "        \"gdaldriver\":\"GTiff\",\n",
    "        \"resolution\":1.0,\n",
    "        \"window_size\":8,\n",
    "         \"origin_x\":\"%.3f\",\n",
    "        \"origin_y\":\"%.3f\",\n",
    "        \"width\":\"%i\",\n",
    "        \"height\":\"%i\"\n",
    "    }\n",
    "]\"\"\"% (als_t1, als_t1_dtm, origin_left, origin_bottom, dsm_width, dsm_height)\n",
    "\n",
    "#using the extent defined by the uls data, so the difference calculation is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e035bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline(json_dtm)\n",
    "exe = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c4248",
   "metadata": {},
   "source": [
    "**3.2 Create raster from ALS 2021:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d4b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_t2_dtm = als_t2.replace(\".laz\", \"_dtm_1m.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbaab56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = als_t2\n",
    "f = open(filename, \"rb+\")\n",
    "f.seek(6)\n",
    "f.write(bytes([17, 0, 0, 0]));\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bf7b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dtm = \"\"\"[\n",
    "    \"%s\",\n",
    "    {\n",
    "        \"type\":\"writers.gdal\",\n",
    "        \"filename\": \"%s\",\n",
    "        \"output_type\":\"min\",\n",
    "        \"gdaldriver\":\"GTiff\",\n",
    "        \"resolution\":1.0,\n",
    "        \"window_size\":8,\n",
    "        \"origin_x\":\"%.3f\",\n",
    "        \"origin_y\":\"%.3f\",\n",
    "        \"width\":\"%i\",\n",
    "        \"height\":\"%i\"\n",
    "    }\n",
    "]\"\"\"% (als_t2, als_t2_dtm, origin_left, origin_bottom, dsm_width, dsm_height) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fc15b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline(json_dtm)\n",
    "exe = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5d976",
   "metadata": {},
   "source": [
    "**3.3 Calculate difference of rasters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcc036ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(als_t1_dtm) as src:\n",
    "    als_t1_data = src.read(1, masked=True)\n",
    "    dsm_meta = src.profile\n",
    "    \n",
    "with rio.open(als_t2_dtm) as src:\n",
    "    als_t2_data = src.read(1, masked=True)\n",
    "    dsm_meta = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c92153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_diff = als_t1_data - als_t2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c2717b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(als_diff, cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acf71c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "als_diff_file = 'als_diff.tif'\n",
    "\n",
    "with rio.open(als_diff_file, 'w', **dsm_meta) as ff:\n",
    "    ff.write(als_diff, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d396a",
   "metadata": {},
   "source": [
    "### 4. Compare results of surface change detection: ULS vs ALS\n",
    "\n",
    "We have now calculated the detected change in the rock glacier from ULS data and estimated the detected change if we had flown an ALS acquisition. By comparing the amount of change detected between ULS and ALS, we can determine whether an ALS acquisition would have been sufficient to detect surface change using our rudimentary method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4404e5e",
   "metadata": {},
   "source": [
    "First, we open and plot the two DTMs representing the amount of surface change next to eachother for a visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "953b84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(uls_diff_file) as src:\n",
    "    uls_diff = src.read(1, masked=True)\n",
    "    dsm_meta = src.profile\n",
    "\n",
    "with rio.open(als_diff_file) as src:\n",
    "    als_diff = src.read(1, masked=True)\n",
    "    dsm_meta = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9d6d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ALS Surface Change')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "fig.suptitle('Surface Change Comparison')\n",
    "\n",
    "ax1.imshow(uls_diff, cmap='pink')\n",
    "ax1.set_title('ULS Surface Change')\n",
    "ax2.imshow(als_diff, cmap='pink')\n",
    "ax2.set_title('ALS Surface Change')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd9d35",
   "metadata": {},
   "source": [
    "The visual comparison did not reveal any major differences between the surface change detection. To gain a more detailed insight, we can calculate the difference of between the ULS difference and the ALS difference rasters. Thereby we can find out exactly by how much the ALS change detection differs from the change detection with the ULS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e668a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_det_diff = uls_diff - als_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d008cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(change_det_diff, cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1f039",
   "metadata": {},
   "source": [
    "Next, we can calculate some statistics for the differences between the ULS and ALS change detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6b4e92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum difference in detected surface change: 112.87696249999954m\n",
      "Median absolute difference in detected surface change: 0.3359375m\n",
      "Arithmetic mean of absolute difference in detected surface change: 0.24289509890524133m\n",
      "Q2 quantile of difference in detected surface change: 0.027932175735031706m\n"
     ]
    }
   ],
   "source": [
    "print('Maximum difference in detected surface change: {}m'.format(np.nanmax(np.abs(change_det_diff))))\n",
    "print('Median absolute difference in detected surface change: {}m'.format(np.nanmedian(np.abs(change_det_diff))))\n",
    "print('Arithmetic mean of absolute difference in detected surface change: {}m'.format(np.nanmean(np.abs(change_det_diff))))\n",
    "#print('Q1 quantile of difference in detected surface change: {}m'.format(np.nanquantile(change_det_diff, 0.25)))\n",
    "print('Q2 quantile of difference in detected surface change: {}m'.format(np.nanquantile(change_det_diff, 0.75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fc0a8",
   "metadata": {},
   "source": [
    "As we can see, small overall differences in the detected magnitude do exist between the ALS and ULS surface change detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f324bd8",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "### 5. Results\n",
    "\n",
    "*Is ALS data sufficient for conducting our surface change analysis?*\n",
    "\n",
    "*Repeat: what is the advantage of conducting ALS vs ULS acquisitions?*\n",
    "\n",
    "**Have another look at the plots and the statistics and try to answer the questions. For our answer, click on the plus symbol to the left of the cell.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c83a01bb",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "We found that the lower density point clouds from ALS deliver a similar amount of information on the areas of surface change but yielded inaccuracies regarding the magnitude of the surface changes. Thus we  can conclude that, to apply this approach in future, point clouds with lower point densities as delivered by ALS acquisitions of the rock glacier would be sufficient to detect the areas where surface change occurred, whereas the ULS data with a higher spatial resoution would be required to accurately measure the magnitude of the change. Since ALS acquisitions can cover large areas relative to ULS, this could prove to be a more cost-efficient acquisition method when monitoring areas of surface change, especially since ALS datasets are often available online via national inventory databases.\n",
    "\n",
    "**Bonus questions:**\n",
    "\n",
    "1. Can you think of other methods of surface change detection?\n",
    "\n",
    "2. Do you think ALS point clouds would be sufficient for these methods?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
