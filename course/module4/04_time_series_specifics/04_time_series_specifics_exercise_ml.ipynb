{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deluxe-luxembourg",
   "metadata": {},
   "source": [
    "# Training a Support vector Machine (SVM) and a Random Forest (RF) for hyperspectral data classification\n",
    "\n",
    "In this notebook, you will train and apply two common Machine Learning classifiers - Support Vewctor Machine and Random Forest for classification of hyperspectral data from Pavia City centre, Italy or Luční Hora, Krkonoše mountains, Czechia.\n",
    "\n",
    "This notebook can be run online using Google Colab (You need a Google account to use Colab). The online notebook is available from **missing link**.\n",
    "\n",
    "Pavia city centre is a common benchmark for hyperspectral data classification and can be obtained from http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes#Pavia_Centre_and_University\n",
    "\n",
    "Our dataset from Luční Hora is currently not publicly available, but we are working on providing it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928ce5d-8cf8-438b-a544-9769100281cc",
   "metadata": {},
   "source": [
    "- *Prerequisities*\n",
    "\t- Google account for accessing Google Colab ([link to notebook](https://colab.research.google.com/drive/17LVAThXbv9sOkGL7JCwRjzSAxumnigrs))\n",
    "\t- If running the notebook in Google Colab, please copy the notebook to your own Google Drive and follow the exercise\n",
    "\t\n",
    "\tor\n",
    "\t\n",
    "\t- Python environment with the necessary libraries ([manual](../../software/software_python.md))\n",
    "\t- Download this notebook (TODO - add link)\n",
    "    - Downloaded data (TODO - add link)\n",
    "    The dataset consists of:\n",
    "        + Hyperspectral RPAS imagery of Luční Hora, Czechia (50.728N, 15.682E) acquired in August of 2020 and resampled to 54 spectral bands with ground sampling distance of 9 cm.\n",
    "        + two rasters with reference data (one for training, the other for testing): BL_training_polygons.shp (shapefile)\n",
    "        + Pretrained models and corresponding classified rasters\n",
    "         \n",
    "- *Tasks*\n",
    "    - Learn how to preprocess imagery for Machine Learning\n",
    "    - Classify the hyperspectral image using SVM or RF\n",
    "\t- Observe how hyperparameter values alter classification results\n",
    "\t- Evaluate your results and compare to our pretrained classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-california",
   "metadata": {},
   "source": [
    "## Structure of this exercise\n",
    "\n",
    "What are you going to encounter during this exercise.\n",
    "\n",
    "0. Load libraries, set paths\n",
    "1. Load and Preprocess training data\n",
    "2. Create/Fit Classifiers  \n",
    "    2A Create/Fit Support Vector Machine  \n",
    "    2B Create/Fit Random Forest\n",
    "3. Apply Classifier\n",
    "4. Evaluate Result\n",
    "5. Sample Solutions  \n",
    "    5A SVM  \n",
    "    5B RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-anger",
   "metadata": {},
   "source": [
    "## 0. Load external libraries and set paths\n",
    "\n",
    "First, we need to import external libraries:\n",
    "\n",
    "- __numpy__ - Arrays to hold our data\n",
    "- __matplotlib.pyplot__ - Draw images\n",
    "\n",
    "- __sklearn.svm / sklearn.ensemble__ - Machine Learning Classifiers\n",
    "- __sklearn.model_selection__ - Cross-validation and hyperparameter tuning implemented in scikit-learn\n",
    "- __sklearn.metrics__ - Compute accuracy metrics using scikit-learn\n",
    "- __sklearn.preprocessing__ - Normalizing input data using scikit-learn\n",
    "\n",
    "- __time.perf_counter__ - Track how long individual functions take to run\n",
    "- __os.path__ - Path manipulation\n",
    "- __tqdm__ - show progress bars during training\n",
    "- __joblib__ - Saving and loading trained classifiers\n",
    "\n",
    "- __image_preprocessing__ - Our library holding functions for image tiling, preprocessing, etc.\n",
    "- __inference_utils__ - Our library for correctly exporting classifed images\n",
    "- __visualisation_utils__ - Our library for visualising the data\n",
    "\n",
    "Two external libraries are not imported directly in this notebook, but are used by functions in _image_preprocessing_ and _inference_utils_:\n",
    "\n",
    "- __gdal__ - Manipulates spatial data\n",
    "- __scipy.io__ - Reads .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import perf_counter\n",
    "from os.path import join\n",
    "import scipy\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import notebook as tqdm\n",
    "from joblib import dump, load\n",
    "\n",
    "import image_preprocessing\n",
    "import inference_utils\n",
    "import visualisation_utils\n",
    "\n",
    "# GLOBAL SETTINGS\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "np.set_printoptions(precision=2, suppress=True)  # Array print precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset name (used by visualisation functions) - 'krknonose' or 'pavia_centre'\n",
    "# default: 'pavia_centre'\n",
    "ds_name = 'krkonose'\n",
    "\n",
    "# Get a list of class names\n",
    "_, class_names = visualisation_utils._create_colorlist_classnames(ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681f8da",
   "metadata": {},
   "source": [
    "Please fill correct paths to your training and reference rasters (just pointing the _root_path_ variable to the project folder should do):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'f:/datasets/etrainee'\n",
    "# root_path = 'C:/folder/where/this/project/is/saved'\n",
    "\n",
    "# PATHS TO TRAINING DATA\n",
    "# Krkonose\n",
    "imagery_path = join(root_path, 'LH_202008_54bands_9cm.tif')\n",
    "train_path   = join(root_path, 'LH_202008_train.tif')\n",
    "test_path    = join(root_path, 'LH_202008_test.tif')\n",
    "# Pavia\n",
    "#imagery_path = join(root_path, 'Pavia.mat')\n",
    "#train_path   = join(root_path, 'Pavia_gt.mat')\n",
    "#test_path    = join(root_path, 'Pavia_gt.mat')\n",
    "\n",
    "# PATH TO SAVE MODELS\n",
    "model_save_folder = join(root_path, 'models')\n",
    "\n",
    "# PATH TO SAVE CLASSIFIED IMAGE\n",
    "out_path_svm = join(root_path, 'results/Krkonose_SVM.tif')\n",
    "out_path_rf  = join(root_path, 'results/Krkonose_RF.tif')\n",
    "\n",
    "# PATH TO THE SAMPLE RESULTS\n",
    "sample_result_path_svm = join(root_path, 'sample_results/SVM_sample_result.tif')\n",
    "sample_result_path_rf  = join(root_path, 'sample_results/RF_sample_result.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-velvet",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-tongue",
   "metadata": {},
   "source": [
    "### 1.1. Data loading into NumPy\n",
    "Let's start by reading an image into a numpy array, we do this in the background using GDAL.\n",
    "\n",
    "The result of our function is a dictionary named loaded_raster, which contains two numpy arrays under keys _imagery_ and _reference_. As we can see, the loaded hyperspectral dataset has 1088 by 1088 pixels with 54 spectral bands. The raster containing our reference data has the same dimensions in height and width.\n",
    "\n",
    "For loading most raster datasets, we created a _read_gdal()_ function in the _image_preprocessing_ module. But loading .mat files for the Pavia City Centre requires a specific function (_read_pavia_centre()_). Both _read_pavia_centre()_ and _read_gdal()_ return a dictionary containing two numpy arrays with keys _imagery_ and _reference_.\n",
    "\n",
    "If using the Pavia City Centre dataset, you may notice that the original image has a shape of (1096, 1096, 102), but to make the data easier to tile for neural networks, we crop the image to (1088, 1088, 102) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_raster = image_preprocessing.read_gdal(imagery_path, train_path)\n",
    "#loaded_raster = image_preprocessing.read_pavia_centre(imagery_path,\n",
    "    # train_path, out_shape=(1088, 1088, 102))\n",
    "\n",
    "print(f'Tiled imagery shape {loaded_raster[\"imagery\"].shape}')\n",
    "print(f'Tiled reference shape {loaded_raster[\"reference\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_utils.show_img_ref(loaded_raster[\"imagery\"][:, :, [25, 15, 5]],\n",
    "                                 loaded_raster[\"reference\"], ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-harris",
   "metadata": {},
   "source": [
    "### 1.2. Flatten array\n",
    "We will be using SVM and RF to classify individual pixels, therefore we can transform the 3D image (height, width, spectral bands) to a 2D array (length, spectral bands). This transformation destroys spatial relationships within the image, however the classifiers can only use 1D features anyway and it simplifies the next step (filtering NoData)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_shape = loaded_raster['imagery'].shape\n",
    "\n",
    "flat_arrs = {}\n",
    "flat_arrs['imagery'] = loaded_raster['imagery'].reshape(\n",
    "    orig_shape[0]*orig_shape[1], orig_shape[2])\n",
    "flat_arrs['reference'] = loaded_raster['reference'].reshape(\n",
    "    orig_shape[0]*orig_shape[1])\n",
    "\n",
    "print(f'The flat imagery array has shape {flat_arrs[\"imagery\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-federal",
   "metadata": {},
   "source": [
    "### 1.3. Filter out NoData pixels\n",
    "\n",
    "We can only train the classifier on pixels with a reference value, therefore we remove all pixels belonging to class 0 (NoData). This operation reduces our training dataset from ~1.23 milion to ~50 thousand pixels. We then visualise the spectral curves of individual pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_arrs = {}\n",
    "filtered_arrs['imagery'] = flat_arrs['imagery'][flat_arrs['reference'] > 0]\n",
    "filtered_arrs['reference'] = flat_arrs['reference'][flat_arrs['reference'] > 0]\n",
    "\n",
    "print(f'The filtered array has shape {filtered_arrs[\"imagery\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-syntax",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel_number = 300\n",
    "visualisation_utils.show_spectral_curve(filtered_arrs, pixel_number,\n",
    "                                        ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-christopher",
   "metadata": {},
   "source": [
    "### 1.4. Subsetting the training data\n",
    "With the whole training dataset, the training procedure may take relatively long. Instead we randomly select a number of samples from each class for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many training samples do we have for each class?\n",
    "unique, counts = np.unique(filtered_arrs['reference'], return_counts=True)\n",
    "print(f'The individual classes contain {counts} training pixels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples per class do we pick?\n",
    "n_class_samples = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array for random indices\n",
    "indices_random = np.zeros((n_class_samples*len(unique)), dtype=np.uint32)\n",
    "sorted_reference = np.argsort(filtered_arrs['reference'])\n",
    "\n",
    "# Randomly select the same number of indices from each class\n",
    "start = 0\n",
    "for idx in range(len(counts)):\n",
    "    indices_random[(idx*n_class_samples):((idx+1)*n_class_samples)] = np.random.choice(\n",
    "        sorted_reference[start:(start+counts[idx])], size=n_class_samples, replace=False)\n",
    "    start += counts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the original arrays using the random indices\n",
    "subset_arrs = {}\n",
    "subset_arrs['imagery'] = filtered_arrs['imagery'][indices_random, :]\n",
    "subset_arrs['reference'] = filtered_arrs['reference'][indices_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-parameter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's check how many pixels are in each class now\n",
    "unique, counts = np.unique(subset_arrs['reference'], return_counts=True)\n",
    "print(f'Now, the individual classes contain {counts} training pixels.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6d07b",
   "metadata": {},
   "source": [
    "Let's visualise some of the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-manitoba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel_number = 300\n",
    "visualisation_utils.show_spectral_curve(subset_arrs, pixel_number,\n",
    "                                        ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-simpson",
   "metadata": {},
   "source": [
    "### 1.5. Data scaling\n",
    "After filtering the training data, we can move onto data scaling. In Machine Learning, it is common to scale all features before classification, because many classifiers assume that all features vary on comparable scales  and that each feature has values close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_arrs = {}\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(flat_arrs['imagery'])\n",
    "preprocessed_arrs['imagery'] = scaler.transform(subset_arrs['imagery'])\n",
    "preprocessed_arrs['reference'] = subset_arrs['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-provincial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel_number = 5\n",
    "visualisation_utils.show_spectral_curve(preprocessed_arrs, pixel_number,\n",
    "                                        ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-culture",
   "metadata": {},
   "source": [
    "## 2A. Support Vector Machine definition and training\n",
    "\n",
    "After preprocessing our data, we can move onto defining our machine learning models. You can either train your own classifiers or use ones we already trained for you (_sample_results/SVM_sample_trained.joblib_). In case you are using the pretrained SVM, skip ahead to section 2A.3.\n",
    "\n",
    "This training uses a support vector machine implementation from scikit-learn, a popular Machine Learning library for Python. The documentation is available at [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-laugh",
   "metadata": {},
   "source": [
    "### 2A.1. Find most suitable parameters\n",
    "\n",
    "To function proprely, SVM has to have suitable values for some hyperparameters. A common approach is to try different values for the hyperparameters, for example kernel, degree, C and gamma.\n",
    "\n",
    "Scikit-Learn makes this easy using RandomizedSearch or GridSearch, these functions train the classifier multiple times using different hyperparameter values and determine the most suitable combination. Each combination of hyperparameter values is tried multiple times using cross-validation (out-of-sample testing).\n",
    "\n",
    "Run either the cell with RandomizedSearchCV or with GridSearchCV, while Grid Search may be able to find mor suitable hyperparameters, Randomized Search will likely also find suitable solutions in a much shorter amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define potential hyperparameter values for the SVM (values to try)\n",
    "parameters_svm = {\n",
    "    'kernel': ['poly', 'rbf'],               # Define the kernel function\n",
    "    'degree': [2, 3],                        # Degree of polynomial used for the 'poly' kernel\n",
    "    'C': [0.1, 1, 10, 100, 1000, 10000],     # Define the penalty value\n",
    "    'gamma': [.00001, .0001, .001, .01, .1], # Kernel parameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and run the optimization\n",
    "opt = RandomizedSearchCV(SVC(), parameters_svm, cv=5, \n",
    "                         scoring=\"jaccard_micro\", n_iter=8, refit=False,\n",
    "                         verbose=4, n_jobs=-2)\n",
    "opt.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])\n",
    "print(f'The optimisation process identified these parameters as the most suitable: {opt.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and run the optimization\n",
    "opt = GridSearchCV(SVC(), parameters_svm, cv=5, scoring=\"jaccard_micro\", refit=False, verbose=4, n_jobs=-2)\n",
    "opt.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])\n",
    "print(f'The optimisation process identified these parameters as the most suitable: {opt.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-franchise",
   "metadata": {},
   "source": [
    "### 2A.2. Fit\n",
    "The best hyperparameter values identified during cross-validation are then used for training the model on the whole training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**opt.best_params_)\n",
    "\n",
    "svm.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-instrumentation",
   "metadata": {},
   "source": [
    "### 2A.3. Save/load trained SVM for potential future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-voltage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save using joblib.dump(object, filename)\n",
    "model_path = join(model_save_folder, 'SVM.joblib')\n",
    "dump(svm, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load using joblib.load(filename)\n",
    "model_path = join(model_save_folder, 'SVM.joblib')\n",
    "svm = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-fence",
   "metadata": {},
   "source": [
    "## 2B. Random Forest definition and training\n",
    "\n",
    "After preprocessing our data, we can move onto defining our machine learning models. You can either train your own classifiers or use ones we already trained for you (_sample_results/RF_sample_trained.joblib_). In case you are using the pretrained RF, skip ahead to section 2B.3.\n",
    "\n",
    "This training uses a Random Forest implementation from scikit-learn, a popular Machine Learning library for Python. The documentation is available at [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-percentage",
   "metadata": {},
   "source": [
    "### 2B.1. Find most suitable parameters\n",
    "\n",
    "To function proprely, SVM has to have suitable values for some hyperparameters. A common approach is to try different values for the hyperparameters, for example kernel, degree, C and gamma.\n",
    "\n",
    "Scikit-Learn makes this easy using RandomizedSearch or GridSearch, these functions train the classifier multiple times using different hyperparameter values and determine the most suitable combination. Each combination of hyperparameter values is tried multiple times using cross-validation (out-of-sample testing).\n",
    "\n",
    "Run either the cell with RandomizedSearchCV or with GridSearchCV, while Grid Search may be able to find mor suitable hyperparameters, Randomized Search will likely also find suitable solutions in a much shorter amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define potential parameter values for the SVM\n",
    "parameters_rf = {\n",
    "    'n_estimators': [50, 100, 250, 500, 750], # Number of trees in the forest\n",
    "    'max_depth': [3, 5, 10, 20, 50],          # Maximum depth of a tree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-starter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the optimizer and run the optimization\n",
    "opt = RandomizedSearchCV(RandomForestClassifier(), parameters_rf, cv=5, scoring=\"jaccard_macro\", n_iter=8, refit=False, n_jobs=-2, verbose=4)\n",
    "opt.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])\n",
    "print(f'The optimisation process identified these parameters as the most suitable: {opt.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and run the GridSerach optimization\n",
    "opt = GridSearchCV(RandomForestClassifier(), parameters_rf, cv=5, scoring=\"jaccard_micro\", refit=False, n_jobs=-2, verbose=4)\n",
    "opt.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])\n",
    "print(f'The optimisation process identified these parameters as the most suitable: {opt.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-disaster",
   "metadata": {},
   "source": [
    "### 2B.2. Fit\n",
    "The best hyperparameter values identified during cross-validation are then used for training the model on the whole training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**opt.best_params_)\n",
    "\n",
    "rf.fit(X=preprocessed_arrs['imagery'], y=preprocessed_arrs['reference'])\n",
    "rf.score(preprocessed_arrs['imagery'], preprocessed_arrs['reference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-terry",
   "metadata": {},
   "source": [
    "### 2B.3. Save/load trained RF for potential future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-uncle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save using joblib.dump(object, filename)\n",
    "model_path = join(model_save_folder, 'RF.joblib')\n",
    "dump(rf, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load using joblib.load(filename)\n",
    "rf = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-communications",
   "metadata": {},
   "source": [
    "## 3. Model application & evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-conditions",
   "metadata": {},
   "source": [
    "### 3.1. Loading and preprocessing the data\n",
    "\n",
    "Load a raster to classify. This can be the one that we used for training, but it can also be a different raster with the same number of bands.\n",
    "\n",
    "By default, the training raster (_imagery_path_) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster\n",
    "raster = image_preprocessing.read_gdal_with_geoinfo(imagery_path, (0,0))\n",
    "\n",
    "# Flattern spatial dimension of the raster\n",
    "raster_shape = raster['imagery'].shape\n",
    "raster_flat = raster['imagery'].reshape(raster_shape[0]*raster_shape[1],\n",
    "                                        raster_shape[2])\n",
    "\n",
    "# Preprocess(scale) the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(raster_flat)\n",
    "raster_scaled = scaler.transform(raster_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d63b9",
   "metadata": {},
   "source": [
    "### 3.2. Applying the classifier\n",
    "\n",
    "The following snippet applies the classifier to the loaded imagery, and then transforms the flattened array back into a raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select if you want to apply the SVM or RF\n",
    "#model = svm\n",
    "model = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flat = model.predict(raster_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raster = predicted_flat.reshape(raster_shape[0], raster_shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda8415",
   "metadata": {},
   "source": [
    "You can also visualise the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed94cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_utils.show_classified(loaded_raster['imagery'][:, :, [25, 15, 5]],\n",
    "                                    loaded_raster['reference'],\n",
    "                                    predicted_raster, ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-alert",
   "metadata": {},
   "source": [
    "### 3.3. Export resulting raster\n",
    "\n",
    "Export the resulting classified raster into _out_path_ for distribution or further analysis (e.g. validation in GIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose if saving the SVM or RF result\n",
    "#out_path = out_path_svm\n",
    "out_path = out_path_rf\n",
    "\n",
    "inference_utils.export_result(out_path, predicted_raster, raster['geoinfo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40337fd0",
   "metadata": {},
   "source": [
    "## 4. Evaluate Classification Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-bunch",
   "metadata": {},
   "source": [
    "### 4.1. Load Test Raster\n",
    "\n",
    "The test raster is loaded using the same functions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raster\n",
    "test_arr = image_preprocessing.read_gdal(imagery_path, test_path)\n",
    "test_flat = test_arr['reference'].reshape(\n",
    "    test_arr['reference'].shape[0]*test_arr['reference'].shape[1])\n",
    "test_filtered = test_flat[test_flat > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_filtered = predicted_flat[test_flat > 0]\n",
    "test_filtered = test_flat[test_flat > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-picking",
   "metadata": {},
   "source": [
    "### 4.2. Compute accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_filtered, predicted_filtered,\n",
    "      target_names=class_names[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3352cd4",
   "metadata": {},
   "source": [
    "### 4.3. Show Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_utils.show_confusion_matrix(test_filtered, predicted_filtered,\n",
    "                                          ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-insight",
   "metadata": {},
   "source": [
    "## 5A. Sample Solution (SVM)\n",
    "\n",
    "We have generated this result using these training parameters (please note that just using the same training parameters will not yield the same result):\n",
    "\n",
    "- Kernel: Polynomial\n",
    "- Polynom degree: 2\n",
    "- C: 1000\n",
    "- Gamma: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test reference\n",
    "test_arr = image_preprocessing.read_gdal(imagery_path, test_path)\n",
    "test_flat = test_arr['reference'].reshape(\n",
    "    test_arr['reference'].shape[0]*test_arr['reference'].shape[1])\n",
    "test_filtered = test_flat[test_flat > 0]\n",
    "\n",
    "# Read sample result\n",
    "sample_arr = image_preprocessing.read_gdal(imagery_path, sample_result_path_svm)\n",
    "sample_flat = sample_arr['reference'].reshape(\n",
    "    sample_arr['reference'].shape[0] * sample_arr['reference'].shape[1])\n",
    "sample_filtered = sample_flat[test_flat > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the sample result\n",
    "visualisation_utils.show_classified(loaded_raster['imagery'][:, :, [25, 15, 5]],\n",
    "                                    loaded_raster['reference'],\n",
    "                                    sample_arr['reference'],\n",
    "                                    ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7e134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a classification report for the sample result\n",
    "print(classification_report(test_filtered, sample_filtered,\n",
    "      target_names=class_names[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954dee20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a Confusion matrix for the sample result\n",
    "visualisation_utils.show_confusion_matrix(test_filtered, sample_filtered,\n",
    "                                          ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd86483",
   "metadata": {},
   "source": [
    "## 5B. Sample Solution (RF)\n",
    "\n",
    "We have generated this result using these training parameters (please note that just using the same training parameters will not yield the same result):\n",
    "\n",
    "- Number of trees: 750\n",
    "- Maximium tree depth: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575fd4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read test reference\n",
    "test_arr = image_preprocessing.read_gdal(imagery_path, test_path)\n",
    "test_flat = test_arr['reference'].reshape(\n",
    "    test_arr['reference'].shape[0]*test_arr['reference'].shape[1])\n",
    "test_filtered = test_flat[test_flat > 0]\n",
    "\n",
    "# Read sample result\n",
    "sample_arr = image_preprocessing.read_gdal(imagery_path, sample_result_path_rf)\n",
    "sample_flat = sample_arr['reference'].reshape(\n",
    "    sample_arr['reference'].shape[0] * sample_arr['reference'].shape[1])\n",
    "sample_filtered = sample_flat[test_flat > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3e9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise the sample result\n",
    "visualisation_utils.show_classified(loaded_raster['imagery'][:, :, [25, 15, 5]],\n",
    "                                    loaded_raster['reference'],\n",
    "                                    sample_arr['reference'],\n",
    "                                    ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a classification report for the sample result\n",
    "print(classification_report(test_filtered, sample_filtered,\n",
    "      target_names=class_names[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a Confusion matrix for the sample result\n",
    "visualisation_utils.show_confusion_matrix(test_filtered, sample_filtered,\n",
    "                                          ds_name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bae73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
